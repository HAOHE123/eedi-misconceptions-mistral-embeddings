nohup: ignoring input
[2024-11-20 10:30:18,345] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-11-20 10:30:19,411] [INFO] [comm.py:652:init_distributed] cdb=None
[2024-11-20 10:30:19,411] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
11/20/2024 10:30:19 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
11/20/2024 10:30:19 - INFO - __main__ -   Training/evaluation parameters RetrieverTrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=True,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=1800,
debug=[],
deepspeed=stage2.json,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=no,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=64,
gradient_checkpointing=True,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0002,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=../../../../model_save/v3_round1_qlora_recall_top_100_for_rank_model/runs/Nov20_10-30-17_autodl-container-499541b7fe-5f1df067,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
loss_type=only logits,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
output_dir=../../../../model_save/v3_round1_qlora_recall_top_100_for_rank_model,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=../../../../model_save/v3_round1_qlora_recall_top_100_for_rank_model,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=0,
seed=42,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.05,
warmup_steps=0,
weight_decay=0.0,
)
11/20/2024 10:30:19 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='/root/autodl-tmp/bert-models/upstage/SOLAR-10.7B-Instruct-v1.0', peft_model_path='', config_name=None, tokenizer_name=None, use_lora=True, lora_rank=32, lora_alpha=64.0, lora_dropout=0.1, target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'lm_head'], save_merged_lora_model=False, use_flash_attn=False, use_slow_tokenizer=False, low_cpu_mem_usage=False, cache_dir='tmp', token=None, from_peft=None, lora_extra_parameters=None)
11/20/2024 10:30:19 - INFO - __main__ -   Data parameters DataArguments(train_data='../../../../output/v3_round1_qlora_rank_top_50_train.jsonl', train_group_size=16, query_max_len=512, passage_max_len=512, max_example_num_per_dataset=100000000, query_instruction_for_retrieval='A: ', passage_instruction_for_retrieval='B: ', cache_path='./data_dir', load_from_disk=False, load_disk_path=None, save_to_disk=False, save_disk_path=None, num_shards=0, save_max_shard_size='50GB', exit_after_save=False)
training_args.fp16 = False
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:05,  1.44s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:04,  1.45s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:04<00:02,  1.34s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:05<00:01,  1.36s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.19s/it]
model_args.from_peft = None
model_args.use_lora = True
trainable params: 126,984,192 || all params: 10,858,508,288 || trainable%: 1.1694
11/20/2024 10:30:28 - INFO - __main__ -   Config: LlamaConfig {
  "_name_or_path": "/root/autodl-tmp/bert-models/upstage/SOLAR-10.7B-Instruct-v1.0",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "id2label": {
    "0": "LABEL_0"
  },
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "label2id": {
    "LABEL_0": 0
  },
  "max_position_embeddings": 4096,
  "mlp_bias": false,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 48,
  "num_key_value_heads": 8,
  "pad_token_id": 2,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.42.3",
  "use_cache": true,
  "vocab_size": 32000
}

sm0.3
  0%|          | 0/270 [00:00<?, ?it/s]  0%|          | 1/270 [03:13<14:27:10, 193.42s/it]                                                   {'loss': 2.6963, 'grad_norm': 27.427209854125977, 'learning_rate': 0.0, 'epoch': 0.02}
  0%|          | 1/270 [03:13<14:27:10, 193.42s/it]  1%|          | 2/270 [06:22<14:12:27, 190.85s/it]                                                   {'loss': 2.7889, 'grad_norm': 14.352038383483887, 'learning_rate': 5.252990700743872e-05, 'epoch': 0.04}
  1%|          | 2/270 [06:22<14:12:27, 190.85s/it]  1%|          | 3/270 [09:29<14:00:44, 188.93s/it]                                                   {'loss': 2.7873, 'grad_norm': 14.27856159210205, 'learning_rate': 8.325793277315987e-05, 'epoch': 0.05}
  1%|          | 3/270 [09:29<14:00:44, 188.93s/it]  1%|▏         | 4/270 [12:31<13:45:21, 186.17s/it]                                                   {'loss': 2.7389, 'grad_norm': 10.890015602111816, 'learning_rate': 0.00010505981401487743, 'epoch': 0.07}
  1%|▏         | 4/270 [12:31<13:45:21, 186.17s/it]  2%|▏         | 5/270 [15:48<13:59:52, 190.16s/it]                                                   {'loss': 2.588, 'grad_norm': 9.971256256103516, 'learning_rate': 0.00012197066690239247, 'epoch': 0.09}
  2%|▏         | 5/270 [15:48<13:59:52, 190.16s/it]  2%|▏         | 6/270 [18:50<13:45:22, 187.59s/it]                                                   {'loss': 2.8295, 'grad_norm': 25.506996154785156, 'learning_rate': 0.00013578783978059858, 'epoch': 0.11}
  2%|▏         | 6/270 [18:50<13:45:22, 187.59s/it]  3%|▎         | 7/270 [22:02<13:48:21, 188.98s/it]                                                   {'loss': 2.7143, 'grad_norm': 11.953353881835938, 'learning_rate': 0.00014747009299256132, 'epoch': 0.13}
  3%|▎         | 7/270 [22:02<13:48:21, 188.98s/it]  3%|▎         | 8/270 [25:00<13:29:34, 185.40s/it]                                                   {'loss': 2.641, 'grad_norm': 7.253403663635254, 'learning_rate': 0.00015758972102231612, 'epoch': 0.15}
  3%|▎         | 8/270 [25:00<13:29:34, 185.40s/it]  3%|▎         | 9/270 [28:05<13:26:31, 185.41s/it]                                                   {'loss': 2.5481, 'grad_norm': 6.737452507019043, 'learning_rate': 0.00016651586554631973, 'epoch': 0.16}
  3%|▎         | 9/270 [28:05<13:26:31, 185.41s/it]  4%|▎         | 10/270 [31:12<13:25:08, 185.80s/it]                                                    {'loss': 2.5357, 'grad_norm': 7.775282859802246, 'learning_rate': 0.0001745005739098312, 'epoch': 0.18}
  4%|▎         | 10/270 [31:12<13:25:08, 185.80s/it]  4%|▍         | 11/270 [34:23<13:28:34, 187.31s/it]                                                    {'loss': 2.3737, 'grad_norm': 7.110353469848633, 'learning_rate': 0.00018172362122561043, 'epoch': 0.2}
  4%|▍         | 11/270 [34:23<13:28:34, 187.31s/it]  4%|▍         | 12/270 [37:27<13:21:06, 186.30s/it]                                                    {'loss': 2.7619, 'grad_norm': 19.453746795654297, 'learning_rate': 0.0001883177467880373, 'epoch': 0.22}
  4%|▍         | 12/270 [37:27<13:21:06, 186.30s/it]  5%|▍         | 13/270 [40:28<13:10:45, 184.61s/it]                                                    {'loss': 2.5906, 'grad_norm': 7.817075729370117, 'learning_rate': 0.00019438375428058432, 'epoch': 0.24}
  5%|▍         | 13/270 [40:28<13:10:45, 184.61s/it]  5%|▌         | 14/270 [43:35<13:11:23, 185.48s/it]                                                    {'loss': 2.4894, 'grad_norm': 5.4704461097717285, 'learning_rate': 0.0002, 'epoch': 0.26}
  5%|▌         | 14/270 [43:35<13:11:23, 185.48s/it]  6%|▌         | 15/270 [46:46<13:14:52, 187.03s/it]                                                    {'loss': 2.6929, 'grad_norm': 18.91044807434082, 'learning_rate': 0.0002, 'epoch': 0.27}
  6%|▌         | 15/270 [46:46<13:14:52, 187.03s/it]  6%|▌         | 16/270 [49:54<13:13:43, 187.49s/it]                                                    {'loss': 2.5675, 'grad_norm': 4.080060005187988, 'learning_rate': 0.00019921875000000001, 'epoch': 0.29}
  6%|▌         | 16/270 [49:54<13:13:43, 187.49s/it]  6%|▋         | 17/270 [53:00<13:08:32, 187.01s/it]                                                    {'loss': 2.3322, 'grad_norm': 4.693990707397461, 'learning_rate': 0.00019843750000000002, 'epoch': 0.31}
  6%|▋         | 17/270 [53:00<13:08:32, 187.01s/it]  7%|▋         | 18/270 [56:07<13:05:23, 187.00s/it]                                                    {'loss': 2.7389, 'grad_norm': 15.724780082702637, 'learning_rate': 0.00019765625, 'epoch': 0.33}
  7%|▋         | 18/270 [56:07<13:05:23, 187.00s/it]  7%|▋         | 19/270 [59:09<12:55:23, 185.35s/it]                                                    {'loss': 2.2987, 'grad_norm': 3.9529855251312256, 'learning_rate': 0.000196875, 'epoch': 0.35}
  7%|▋         | 19/270 [59:09<12:55:23, 185.35s/it]  7%|▋         | 20/270 [1:02:22<13:02:46, 187.87s/it]                                                      {'loss': 2.3829, 'grad_norm': 4.2694292068481445, 'learning_rate': 0.00019609375, 'epoch': 0.37}
  7%|▋         | 20/270 [1:02:22<13:02:46, 187.87s/it]  8%|▊         | 21/270 [1:05:30<12:59:47, 187.90s/it]                                                      {'loss': 2.4031, 'grad_norm': 5.412216663360596, 'learning_rate': 0.0001953125, 'epoch': 0.38}
  8%|▊         | 21/270 [1:05:30<12:59:47, 187.90s/it]  8%|▊         | 22/270 [1:08:30<12:46:41, 185.49s/it]                                                      {'loss': 2.2074, 'grad_norm': 4.587088108062744, 'learning_rate': 0.00019453125000000002, 'epoch': 0.4}
  8%|▊         | 22/270 [1:08:30<12:46:41, 185.49s/it]  9%|▊         | 23/270 [1:11:31<12:37:30, 184.01s/it]                                                      {'loss': 2.2124, 'grad_norm': 4.434535503387451, 'learning_rate': 0.00019375000000000002, 'epoch': 0.42}
  9%|▊         | 23/270 [1:11:31<12:37:30, 184.01s/it]  9%|▉         | 24/270 [1:14:33<12:32:52, 183.63s/it]                                                      {'loss': 2.2255, 'grad_norm': 4.5077595710754395, 'learning_rate': 0.00019296875, 'epoch': 0.44}
  9%|▉         | 24/270 [1:14:33<12:32:52, 183.63s/it]  9%|▉         | 25/270 [1:17:39<12:32:35, 184.31s/it]                                                      {'loss': 2.3146, 'grad_norm': 4.243252277374268, 'learning_rate': 0.0001921875, 'epoch': 0.46}
  9%|▉         | 25/270 [1:17:39<12:32:35, 184.31s/it] 10%|▉         | 26/270 [1:20:48<12:34:39, 185.57s/it]                                                      {'loss': 2.2949, 'grad_norm': 4.636098384857178, 'learning_rate': 0.00019140625, 'epoch': 0.48}
 10%|▉         | 26/270 [1:20:48<12:34:39, 185.57s/it] 10%|█         | 27/270 [1:23:44<12:19:53, 182.69s/it]                                                      {'loss': 2.1885, 'grad_norm': 5.800419330596924, 'learning_rate': 0.000190625, 'epoch': 0.49}
 10%|█         | 27/270 [1:23:44<12:19:53, 182.69s/it] 10%|█         | 28/270 [1:26:45<12:15:05, 182.26s/it]                                                      {'loss': 2.1556, 'grad_norm': 4.779119491577148, 'learning_rate': 0.00018984375000000002, 'epoch': 0.51}
 10%|█         | 28/270 [1:26:45<12:15:05, 182.26s/it] 11%|█         | 29/270 [1:29:47<12:11:51, 182.20s/it]                                                      {'loss': 2.1304, 'grad_norm': 4.816565036773682, 'learning_rate': 0.00018906250000000002, 'epoch': 0.53}
 11%|█         | 29/270 [1:29:47<12:11:51, 182.20s/it] 11%|█         | 30/270 [1:32:48<12:06:45, 181.69s/it]                                                      {'loss': 2.2392, 'grad_norm': 5.485330581665039, 'learning_rate': 0.00018828125, 'epoch': 0.55}
 11%|█         | 30/270 [1:32:48<12:06:45, 181.69s/it] 11%|█▏        | 31/270 [1:35:54<12:09:08, 183.05s/it]                                                      {'loss': 2.2843, 'grad_norm': 4.61952018737793, 'learning_rate': 0.0001875, 'epoch': 0.57}
 11%|█▏        | 31/270 [1:35:54<12:09:08, 183.05s/it] 12%|█▏        | 32/270 [1:38:50<11:58:17, 181.08s/it]                                                      {'loss': 2.1404, 'grad_norm': 4.471529960632324, 'learning_rate': 0.00018671875, 'epoch': 0.59}
 12%|█▏        | 32/270 [1:38:50<11:58:17, 181.08s/it] 12%|█▏        | 33/270 [1:41:51<11:55:19, 181.09s/it]                                                      {'loss': 2.306, 'grad_norm': 4.503290176391602, 'learning_rate': 0.0001859375, 'epoch': 0.6}
 12%|█▏        | 33/270 [1:41:51<11:55:19, 181.09s/it] 13%|█▎        | 34/270 [1:45:02<12:03:35, 183.96s/it]                                                      {'loss': 2.198, 'grad_norm': 3.6157066822052, 'learning_rate': 0.00018515625000000002, 'epoch': 0.62}
 13%|█▎        | 34/270 [1:45:02<12:03:35, 183.96s/it] 13%|█▎        | 35/270 [1:48:11<12:05:57, 185.35s/it]                                                      {'loss': 2.1874, 'grad_norm': 3.3343145847320557, 'learning_rate': 0.000184375, 'epoch': 0.64}
 13%|█▎        | 35/270 [1:48:11<12:05:57, 185.35s/it] 13%|█▎        | 36/270 [1:51:03<11:47:50, 181.50s/it]                                                      {'loss': 2.1659, 'grad_norm': 3.671325206756592, 'learning_rate': 0.00018359375, 'epoch': 0.66}
 13%|█▎        | 36/270 [1:51:03<11:47:50, 181.50s/it] 14%|█▎        | 37/270 [1:54:08<11:48:27, 182.44s/it]                                                      {'loss': 2.0825, 'grad_norm': 3.43448543548584, 'learning_rate': 0.0001828125, 'epoch': 0.68}
 14%|█▎        | 37/270 [1:54:08<11:48:27, 182.44s/it] 14%|█▍        | 38/270 [1:57:05<11:38:45, 180.71s/it]                                                      {'loss': 2.2019, 'grad_norm': 3.6283984184265137, 'learning_rate': 0.00018203125, 'epoch': 0.69}
 14%|█▍        | 38/270 [1:57:05<11:38:45, 180.71s/it] 14%|█▍        | 39/270 [2:00:06<11:37:06, 181.07s/it]                                                      {'loss': 2.123, 'grad_norm': 3.8908190727233887, 'learning_rate': 0.00018125000000000001, 'epoch': 0.71}
 14%|█▍        | 39/270 [2:00:06<11:37:06, 181.07s/it] 15%|█▍        | 40/270 [2:03:17<11:45:08, 183.95s/it]                                                      {'loss': 2.1067, 'grad_norm': 3.9359309673309326, 'learning_rate': 0.00018046875000000002, 'epoch': 0.73}
 15%|█▍        | 40/270 [2:03:17<11:45:08, 183.95s/it] 15%|█▌        | 41/270 [2:06:21<11:41:34, 183.82s/it]                                                      {'loss': 2.0554, 'grad_norm': 4.105099678039551, 'learning_rate': 0.0001796875, 'epoch': 0.75}
 15%|█▌        | 41/270 [2:06:21<11:41:34, 183.82s/it] 16%|█▌        | 42/270 [2:09:32<11:47:17, 186.13s/it]                                                      {'loss': 2.0608, 'grad_norm': 4.522162437438965, 'learning_rate': 0.00017890625, 'epoch': 0.77}
 16%|█▌        | 42/270 [2:09:32<11:47:17, 186.13s/it] 16%|█▌        | 43/270 [2:12:37<11:42:12, 185.61s/it]                                                      {'loss': 2.1695, 'grad_norm': 3.984708547592163, 'learning_rate': 0.000178125, 'epoch': 0.79}
 16%|█▌        | 43/270 [2:12:37<11:42:12, 185.61s/it] 16%|█▋        | 44/270 [2:15:29<11:24:34, 181.74s/it]                                                      {'loss': 2.1805, 'grad_norm': 3.29494309425354, 'learning_rate': 0.00017734375, 'epoch': 0.8}
 16%|█▋        | 44/270 [2:15:29<11:24:34, 181.74s/it] 17%|█▋        | 45/270 [2:18:32<11:22:55, 182.11s/it]                                                      {'loss': 2.1393, 'grad_norm': 4.109379291534424, 'learning_rate': 0.00017656250000000002, 'epoch': 0.82}
 17%|█▋        | 45/270 [2:18:32<11:22:55, 182.11s/it] 17%|█▋        | 46/270 [2:21:34<11:19:47, 182.09s/it]                                                      {'loss': 2.2351, 'grad_norm': 4.741106986999512, 'learning_rate': 0.00017578125000000002, 'epoch': 0.84}
 17%|█▋        | 46/270 [2:21:34<11:19:47, 182.09s/it] 17%|█▋        | 47/270 [2:24:30<11:09:35, 180.16s/it]                                                      {'loss': 2.0612, 'grad_norm': 3.7793805599212646, 'learning_rate': 0.000175, 'epoch': 0.86}
 17%|█▋        | 47/270 [2:24:30<11:09:35, 180.16s/it] 18%|█▊        | 48/270 [2:27:36<11:13:25, 182.01s/it]                                                      {'loss': 2.0878, 'grad_norm': 4.1521315574646, 'learning_rate': 0.00017421875, 'epoch': 0.88}
 18%|█▊        | 48/270 [2:27:36<11:13:25, 182.01s/it] 18%|█▊        | 49/270 [2:30:36<11:08:07, 181.39s/it]                                                      {'loss': 2.08, 'grad_norm': 5.15360164642334, 'learning_rate': 0.0001734375, 'epoch': 0.9}
 18%|█▊        | 49/270 [2:30:36<11:08:07, 181.39s/it] 19%|█▊        | 50/270 [2:33:45<11:13:28, 183.68s/it]                                                      {'loss': 2.1313, 'grad_norm': 3.4489667415618896, 'learning_rate': 0.00017265625, 'epoch': 0.91}
 19%|█▊        | 50/270 [2:33:45<11:13:28, 183.68s/it] 19%|█▉        | 51/270 [2:36:48<11:09:30, 183.43s/it]                                                      {'loss': 2.0701, 'grad_norm': 3.7534024715423584, 'learning_rate': 0.00017187500000000002, 'epoch': 0.93}
 19%|█▉        | 51/270 [2:36:48<11:09:30, 183.43s/it] 19%|█▉        | 52/270 [2:39:47<11:01:27, 182.05s/it]                                                      {'loss': 2.2671, 'grad_norm': 4.45546817779541, 'learning_rate': 0.00017109375, 'epoch': 0.95}
 19%|█▉        | 52/270 [2:39:47<11:01:27, 182.05s/it] 20%|█▉        | 53/270 [2:42:55<11:05:17, 183.95s/it]                                                      {'loss': 2.1872, 'grad_norm': 5.0273261070251465, 'learning_rate': 0.0001703125, 'epoch': 0.97}
 20%|█▉        | 53/270 [2:42:55<11:05:17, 183.95s/it] 20%|██        | 54/270 [2:46:03<11:06:41, 185.19s/it]                                                      {'loss': 2.0844, 'grad_norm': 3.3822529315948486, 'learning_rate': 0.00016953125, 'epoch': 0.99}
 20%|██        | 54/270 [2:46:03<11:06:41, 185.19s/it] 20%|██        | 55/270 [2:49:08<11:03:06, 185.05s/it]                                                      {'loss': 2.2124, 'grad_norm': 3.2227838039398193, 'learning_rate': 0.00016875, 'epoch': 1.01}
 20%|██        | 55/270 [2:49:08<11:03:06, 185.05s/it] 21%|██        | 56/270 [2:52:10<10:57:06, 184.23s/it]                                                      {'loss': 1.9272, 'grad_norm': 2.932823896408081, 'learning_rate': 0.00016796875000000001, 'epoch': 1.02}
 21%|██        | 56/270 [2:52:10<10:57:06, 184.23s/it] 21%|██        | 57/270 [2:55:18<10:57:20, 185.17s/it]                                                      {'loss': 1.9513, 'grad_norm': 4.198998928070068, 'learning_rate': 0.00016718750000000002, 'epoch': 1.04}
 21%|██        | 57/270 [2:55:18<10:57:20, 185.17s/it] 21%|██▏       | 58/270 [2:58:18<10:48:30, 183.54s/it]                                                      {'loss': 1.7966, 'grad_norm': 4.304139137268066, 'learning_rate': 0.00016640625, 'epoch': 1.06}
 21%|██▏       | 58/270 [2:58:18<10:48:30, 183.54s/it] 22%|██▏       | 59/270 [3:01:24<10:48:51, 184.51s/it]                                                      {'loss': 1.8626, 'grad_norm': 3.4749836921691895, 'learning_rate': 0.000165625, 'epoch': 1.08}
 22%|██▏       | 59/270 [3:01:24<10:48:51, 184.51s/it] 22%|██▏       | 60/270 [3:04:27<10:43:51, 183.96s/it]                                                      {'loss': 1.9283, 'grad_norm': 3.7522077560424805, 'learning_rate': 0.00016484375, 'epoch': 1.1}
 22%|██▏       | 60/270 [3:04:27<10:43:51, 183.96s/it] 23%|██▎       | 61/270 [3:07:38<10:48:33, 186.19s/it]                                                      {'loss': 1.925, 'grad_norm': 4.007265090942383, 'learning_rate': 0.0001640625, 'epoch': 1.12}
 23%|██▎       | 61/270 [3:07:38<10:48:33, 186.19s/it] 23%|██▎       | 62/270 [3:10:40<10:40:54, 184.88s/it]                                                      {'loss': 1.8891, 'grad_norm': 3.7239346504211426, 'learning_rate': 0.00016328125000000001, 'epoch': 1.13}
 23%|██▎       | 62/270 [3:10:40<10:40:54, 184.88s/it] 23%|██▎       | 63/270 [3:13:43<10:36:09, 184.39s/it]                                                      {'loss': 1.9948, 'grad_norm': 5.443739414215088, 'learning_rate': 0.00016250000000000002, 'epoch': 1.15}
 23%|██▎       | 63/270 [3:13:43<10:36:09, 184.39s/it] 24%|██▎       | 64/270 [3:16:56<10:41:09, 186.75s/it]                                                      {'loss': 1.9872, 'grad_norm': 5.153280735015869, 'learning_rate': 0.00016171875, 'epoch': 1.17}
 24%|██▎       | 64/270 [3:16:56<10:41:09, 186.75s/it] 24%|██▍       | 65/270 [3:20:01<10:36:44, 186.36s/it]                                                      {'loss': 1.85, 'grad_norm': 3.7994377613067627, 'learning_rate': 0.0001609375, 'epoch': 1.19}
 24%|██▍       | 65/270 [3:20:01<10:36:44, 186.36s/it] 24%|██▍       | 66/270 [3:23:04<10:30:23, 185.41s/it]                                                      {'loss': 1.8423, 'grad_norm': 3.4811527729034424, 'learning_rate': 0.00016015625, 'epoch': 1.21}
 24%|██▍       | 66/270 [3:23:04<10:30:23, 185.41s/it] 25%|██▍       | 67/270 [3:26:17<10:34:32, 187.55s/it]                                                      {'loss': 1.9521, 'grad_norm': 4.794292449951172, 'learning_rate': 0.000159375, 'epoch': 1.23}
 25%|██▍       | 67/270 [3:26:17<10:34:32, 187.55s/it] 25%|██▌       | 68/270 [3:29:22<10:28:54, 186.80s/it]                                                      {'loss': 1.946, 'grad_norm': 4.386786937713623, 'learning_rate': 0.00015859375000000002, 'epoch': 1.24}
 25%|██▌       | 68/270 [3:29:22<10:28:54, 186.80s/it] 26%|██▌       | 69/270 [3:32:26<10:23:30, 186.12s/it]                                                      {'loss': 1.8605, 'grad_norm': 3.86789608001709, 'learning_rate': 0.00015781250000000002, 'epoch': 1.26}
 26%|██▌       | 69/270 [3:32:26<10:23:30, 186.12s/it] 26%|██▌       | 70/270 [3:35:24<10:11:41, 183.51s/it]                                                      {'loss': 1.8703, 'grad_norm': 4.552361011505127, 'learning_rate': 0.00015703125, 'epoch': 1.28}
 26%|██▌       | 70/270 [3:35:24<10:11:41, 183.51s/it] 26%|██▋       | 71/270 [3:38:27<10:08:42, 183.53s/it]                                                      {'loss': 1.8678, 'grad_norm': 3.914536952972412, 'learning_rate': 0.00015625, 'epoch': 1.3}
 26%|██▋       | 71/270 [3:38:27<10:08:42, 183.53s/it] 27%|██▋       | 72/270 [3:41:34<10:08:14, 184.32s/it]                                                      {'loss': 2.0402, 'grad_norm': 3.7879793643951416, 'learning_rate': 0.00015546875, 'epoch': 1.32}
 27%|██▋       | 72/270 [3:41:34<10:08:14, 184.32s/it] 27%|██▋       | 73/270 [3:44:34<10:01:46, 183.28s/it]                                                      {'loss': 1.9132, 'grad_norm': 3.314011573791504, 'learning_rate': 0.0001546875, 'epoch': 1.33}
 27%|██▋       | 73/270 [3:44:34<10:01:46, 183.28s/it] 27%|██▋       | 74/270 [3:47:40<10:01:16, 184.06s/it]                                                      {'loss': 1.907, 'grad_norm': 3.220989227294922, 'learning_rate': 0.00015390625000000002, 'epoch': 1.35}
 27%|██▋       | 74/270 [3:47:40<10:01:16, 184.06s/it] 28%|██▊       | 75/270 [3:50:47<10:01:04, 184.95s/it]                                                      {'loss': 2.03, 'grad_norm': 4.239379405975342, 'learning_rate': 0.000153125, 'epoch': 1.37}
 28%|██▊       | 75/270 [3:50:47<10:01:04, 184.95s/it] 28%|██▊       | 76/270 [3:53:53<9:58:12, 185.01s/it]                                                      {'loss': 1.9159, 'grad_norm': 3.7981815338134766, 'learning_rate': 0.00015234375, 'epoch': 1.39}
 28%|██▊       | 76/270 [3:53:53<9:58:12, 185.01s/it] 29%|██▊       | 77/270 [3:56:50<9:48:10, 182.85s/it]                                                     {'loss': 1.8592, 'grad_norm': 3.459993362426758, 'learning_rate': 0.0001515625, 'epoch': 1.41}
 29%|██▊       | 77/270 [3:56:50<9:48:10, 182.85s/it] 29%|██▉       | 78/270 [3:59:54<9:46:07, 183.16s/it]                                                     {'loss': 1.8991, 'grad_norm': 3.635481119155884, 'learning_rate': 0.00015078125, 'epoch': 1.43}
 29%|██▉       | 78/270 [3:59:54<9:46:07, 183.16s/it] 29%|██▉       | 79/270 [4:02:56<9:41:35, 182.70s/it]                                                     {'loss': 1.9713, 'grad_norm': 3.5830788612365723, 'learning_rate': 0.00015000000000000001, 'epoch': 1.44}
 29%|██▉       | 79/270 [4:02:56<9:41:35, 182.70s/it] 30%|██▉       | 80/270 [4:06:02<9:42:10, 183.85s/it]                                                     {'loss': 1.8283, 'grad_norm': 3.474025249481201, 'learning_rate': 0.00014921875000000002, 'epoch': 1.46}
 30%|██▉       | 80/270 [4:06:02<9:42:10, 183.85s/it] 30%|███       | 81/270 [4:09:13<9:45:23, 185.84s/it]                                                     {'loss': 2.0435, 'grad_norm': 4.487939357757568, 'learning_rate': 0.0001484375, 'epoch': 1.48}
 30%|███       | 81/270 [4:09:13<9:45:23, 185.84s/it] 30%|███       | 82/270 [4:12:20<9:43:46, 186.31s/it]                                                     {'loss': 1.9653, 'grad_norm': 3.996852397918701, 'learning_rate': 0.00014765625, 'epoch': 1.5}
 30%|███       | 82/270 [4:12:20<9:43:46, 186.31s/it] 31%|███       | 83/270 [4:15:32<9:45:50, 187.97s/it]                                                     {'loss': 2.0272, 'grad_norm': 3.232421636581421, 'learning_rate': 0.000146875, 'epoch': 1.52}
 31%|███       | 83/270 [4:15:32<9:45:50, 187.97s/it] 31%|███       | 84/270 [4:18:33<9:35:42, 185.71s/it]                                                     {'loss': 2.0328, 'grad_norm': 3.2930307388305664, 'learning_rate': 0.00014609375, 'epoch': 1.54}
 31%|███       | 84/270 [4:18:33<9:35:42, 185.71s/it] 31%|███▏      | 85/270 [4:21:42<9:35:35, 186.68s/it]                                                     {'loss': 1.9432, 'grad_norm': 3.189764976501465, 'learning_rate': 0.00014531250000000002, 'epoch': 1.55}
 31%|███▏      | 85/270 [4:21:42<9:35:35, 186.68s/it] 32%|███▏      | 86/270 [4:24:54<9:37:29, 188.31s/it]                                                     {'loss': 1.82, 'grad_norm': 3.0540735721588135, 'learning_rate': 0.00014453125000000002, 'epoch': 1.57}
 32%|███▏      | 86/270 [4:24:54<9:37:29, 188.31s/it] 32%|███▏      | 87/270 [4:28:02<9:34:31, 188.37s/it]                                                     {'loss': 1.8564, 'grad_norm': 4.371145248413086, 'learning_rate': 0.00014375, 'epoch': 1.59}
 32%|███▏      | 87/270 [4:28:02<9:34:31, 188.37s/it] 33%|███▎      | 88/270 [4:31:05<9:26:33, 186.78s/it]                                                     {'loss': 1.8877, 'grad_norm': 5.597303867340088, 'learning_rate': 0.00014296875, 'epoch': 1.61}
 33%|███▎      | 88/270 [4:31:05<9:26:33, 186.78s/it] 33%|███▎      | 89/270 [4:34:11<9:22:27, 186.45s/it]                                                     {'loss': 1.8729, 'grad_norm': 4.442246913909912, 'learning_rate': 0.0001421875, 'epoch': 1.63}
 33%|███▎      | 89/270 [4:34:11<9:22:27, 186.45s/it] 33%|███▎      | 90/270 [4:37:14<9:16:31, 185.51s/it]                                                     {'loss': 1.872, 'grad_norm': 3.898014783859253, 'learning_rate': 0.00014140625, 'epoch': 1.65}
 33%|███▎      | 90/270 [4:37:14<9:16:31, 185.51s/it] 34%|███▎      | 91/270 [4:40:22<9:15:23, 186.17s/it]                                                     {'loss': 1.9474, 'grad_norm': 4.313978672027588, 'learning_rate': 0.00014062500000000002, 'epoch': 1.66}
 34%|███▎      | 91/270 [4:40:22<9:15:23, 186.17s/it] 34%|███▍      | 92/270 [4:43:24<9:08:20, 184.84s/it]                                                     {'loss': 1.9687, 'grad_norm': 4.191346645355225, 'learning_rate': 0.00013984375, 'epoch': 1.68}
 34%|███▍      | 92/270 [4:43:24<9:08:20, 184.84s/it] 34%|███▍      | 93/270 [4:46:27<9:03:41, 184.30s/it]                                                     {'loss': 1.7628, 'grad_norm': 3.6809496879577637, 'learning_rate': 0.0001390625, 'epoch': 1.7}
 34%|███▍      | 93/270 [4:46:27<9:03:41, 184.30s/it] 35%|███▍      | 94/270 [4:49:38<9:06:35, 186.34s/it]                                                     {'loss': 1.8879, 'grad_norm': 4.535181999206543, 'learning_rate': 0.00013828125, 'epoch': 1.72}
 35%|███▍      | 94/270 [4:49:38<9:06:35, 186.34s/it] 35%|███▌      | 95/270 [4:52:41<9:00:49, 185.43s/it]                                                     {'loss': 1.9768, 'grad_norm': 5.683986186981201, 'learning_rate': 0.0001375, 'epoch': 1.74}
 35%|███▌      | 95/270 [4:52:41<9:00:49, 185.43s/it] 36%|███▌      | 96/270 [4:55:46<8:57:10, 185.23s/it]                                                     {'loss': 1.8143, 'grad_norm': 4.328414440155029, 'learning_rate': 0.00013671875, 'epoch': 1.76}
 36%|███▌      | 96/270 [4:55:46<8:57:10, 185.23s/it] 36%|███▌      | 97/270 [4:58:49<8:52:42, 184.75s/it]                                                     {'loss': 1.9394, 'grad_norm': 3.615511178970337, 'learning_rate': 0.00013593750000000002, 'epoch': 1.77}
 36%|███▌      | 97/270 [4:58:49<8:52:42, 184.75s/it] 36%|███▋      | 98/270 [5:01:54<8:49:18, 184.64s/it]                                                     {'loss': 1.8704, 'grad_norm': 4.450626850128174, 'learning_rate': 0.00013515625, 'epoch': 1.79}
 36%|███▋      | 98/270 [5:01:54<8:49:18, 184.64s/it] 37%|███▋      | 99/270 [5:05:02<8:49:21, 185.74s/it]                                                     {'loss': 1.9189, 'grad_norm': 4.458741664886475, 'learning_rate': 0.000134375, 'epoch': 1.81}
 37%|███▋      | 99/270 [5:05:02<8:49:21, 185.74s/it] 37%|███▋      | 100/270 [5:08:10<8:48:05, 186.39s/it]                                                      {'loss': 1.7921, 'grad_norm': 3.1365160942077637, 'learning_rate': 0.00013359375, 'epoch': 1.83}
 37%|███▋      | 100/270 [5:08:10<8:48:05, 186.39s/it] 37%|███▋      | 101/270 [5:11:15<8:43:42, 185.93s/it]                                                      {'loss': 1.9101, 'grad_norm': 4.450700759887695, 'learning_rate': 0.0001328125, 'epoch': 1.85}
 37%|███▋      | 101/270 [5:11:15<8:43:42, 185.93s/it] 38%|███▊      | 102/270 [5:14:19<8:39:22, 185.49s/it]                                                      {'loss': 1.8472, 'grad_norm': 4.301601409912109, 'learning_rate': 0.00013203125000000001, 'epoch': 1.87}
 38%|███▊      | 102/270 [5:14:19<8:39:22, 185.49s/it] 38%|███▊      | 103/270 [5:17:29<8:39:56, 186.81s/it]                                                      {'loss': 1.9186, 'grad_norm': 4.44875431060791, 'learning_rate': 0.00013125000000000002, 'epoch': 1.88}
 38%|███▊      | 103/270 [5:17:29<8:39:56, 186.81s/it] 39%|███▊      | 104/270 [5:20:37<8:37:15, 186.96s/it]                                                      {'loss': 1.9741, 'grad_norm': 5.117131233215332, 'learning_rate': 0.00013046875, 'epoch': 1.9}
 39%|███▊      | 104/270 [5:20:37<8:37:15, 186.96s/it] 39%|███▉      | 105/270 [5:23:37<8:28:55, 185.06s/it]                                                      {'loss': 1.8658, 'grad_norm': 3.9733619689941406, 'learning_rate': 0.0001296875, 'epoch': 1.92}
 39%|███▉      | 105/270 [5:23:37<8:28:55, 185.06s/it] 39%|███▉      | 106/270 [5:26:46<8:29:07, 186.27s/it]                                                      {'loss': 1.9059, 'grad_norm': 4.773782730102539, 'learning_rate': 0.00012890625, 'epoch': 1.94}
 39%|███▉      | 106/270 [5:26:46<8:29:07, 186.27s/it] 40%|███▉      | 107/270 [5:29:52<8:25:22, 186.03s/it]                                                      {'loss': 1.822, 'grad_norm': 3.502262592315674, 'learning_rate': 0.000128125, 'epoch': 1.96}
 40%|███▉      | 107/270 [5:29:52<8:25:22, 186.03s/it] 40%|████      | 108/270 [5:32:54<8:19:18, 184.93s/it]                                                      {'loss': 1.8131, 'grad_norm': 3.6633048057556152, 'learning_rate': 0.00012734375000000002, 'epoch': 1.97}
 40%|████      | 108/270 [5:32:54<8:19:18, 184.93s/it] 40%|████      | 109/270 [5:35:58<8:15:11, 184.54s/it]                                                      {'loss': 1.8569, 'grad_norm': 4.08988618850708, 'learning_rate': 0.0001265625, 'epoch': 1.99}
 40%|████      | 109/270 [5:35:58<8:15:11, 184.54s/it] 41%|████      | 110/270 [5:38:55<8:06:02, 182.27s/it]                                                      {'loss': 1.8547, 'grad_norm': 4.840456008911133, 'learning_rate': 0.00012578125, 'epoch': 2.01}
 41%|████      | 110/270 [5:38:55<8:06:02, 182.27s/it] 41%|████      | 111/270 [5:42:03<8:07:54, 184.12s/it]                                                      {'loss': 1.6696, 'grad_norm': 3.2885520458221436, 'learning_rate': 0.000125, 'epoch': 2.03}
 41%|████      | 111/270 [5:42:03<8:07:54, 184.12s/it] 41%|████▏     | 112/270 [5:45:11<8:07:27, 185.11s/it]                                                      {'loss': 1.6847, 'grad_norm': 3.5119478702545166, 'learning_rate': 0.00012421875, 'epoch': 2.05}
 41%|████▏     | 112/270 [5:45:11<8:07:27, 185.11s/it] 42%|████▏     | 113/270 [5:48:22<8:09:06, 186.92s/it]                                                      {'loss': 1.6999, 'grad_norm': 4.288763523101807, 'learning_rate': 0.0001234375, 'epoch': 2.07}
 42%|████▏     | 113/270 [5:48:22<8:09:06, 186.92s/it] 42%|████▏     | 114/270 [5:51:24<8:02:10, 185.45s/it]                                                      {'loss': 1.7678, 'grad_norm': 4.670230865478516, 'learning_rate': 0.00012265625000000002, 'epoch': 2.08}
 42%|████▏     | 114/270 [5:51:24<8:02:10, 185.45s/it] 43%|████▎     | 115/270 [5:54:24<7:55:10, 183.94s/it]                                                      {'loss': 1.6165, 'grad_norm': 4.152871131896973, 'learning_rate': 0.00012187500000000001, 'epoch': 2.1}
 43%|████▎     | 115/270 [5:54:24<7:55:10, 183.94s/it] 43%|████▎     | 116/270 [5:57:28<7:51:47, 183.82s/it]                                                      {'loss': 1.6556, 'grad_norm': 3.711446762084961, 'learning_rate': 0.00012109375, 'epoch': 2.12}
 43%|████▎     | 116/270 [5:57:28<7:51:47, 183.82s/it] 43%|████▎     | 117/270 [6:00:32<7:48:47, 183.84s/it]                                                      {'loss': 1.6521, 'grad_norm': 3.7377898693084717, 'learning_rate': 0.0001203125, 'epoch': 2.14}
 43%|████▎     | 117/270 [6:00:32<7:48:47, 183.84s/it] 44%|████▎     | 118/270 [6:03:33<7:43:32, 182.97s/it]                                                      {'loss': 1.6484, 'grad_norm': 2.8484554290771484, 'learning_rate': 0.00011953125000000001, 'epoch': 2.16}
 44%|████▎     | 118/270 [6:03:33<7:43:32, 182.97s/it] 44%|████▍     | 119/270 [6:06:45<7:47:16, 185.67s/it]                                                      {'loss': 1.5502, 'grad_norm': 2.6609325408935547, 'learning_rate': 0.00011875, 'epoch': 2.18}
 44%|████▍     | 119/270 [6:06:45<7:47:16, 185.67s/it] 44%|████▍     | 120/270 [6:09:57<7:49:21, 187.74s/it]                                                      {'loss': 1.6037, 'grad_norm': 3.480604887008667, 'learning_rate': 0.00011796875, 'epoch': 2.19}
 44%|████▍     | 120/270 [6:09:57<7:49:21, 187.74s/it] 45%|████▍     | 121/270 [6:13:01<7:43:26, 186.62s/it]                                                      {'loss': 1.6607, 'grad_norm': 4.072551727294922, 'learning_rate': 0.00011718750000000001, 'epoch': 2.21}
 45%|████▍     | 121/270 [6:13:01<7:43:26, 186.62s/it] 45%|████▌     | 122/270 [6:16:12<7:43:11, 187.78s/it]                                                      {'loss': 1.7501, 'grad_norm': 5.303318023681641, 'learning_rate': 0.00011640625, 'epoch': 2.23}
 45%|████▌     | 122/270 [6:16:12<7:43:11, 187.78s/it] 46%|████▌     | 123/270 [6:19:10<7:33:00, 184.90s/it]                                                      {'loss': 1.66, 'grad_norm': 4.32704496383667, 'learning_rate': 0.000115625, 'epoch': 2.25}
 46%|████▌     | 123/270 [6:19:10<7:33:00, 184.90s/it] 46%|████▌     | 124/270 [6:22:10<7:26:45, 183.60s/it]                                                      {'loss': 1.6313, 'grad_norm': 3.2976157665252686, 'learning_rate': 0.00011484375000000001, 'epoch': 2.27}
 46%|████▌     | 124/270 [6:22:10<7:26:45, 183.60s/it] 46%|████▋     | 125/270 [6:25:17<7:25:47, 184.47s/it]                                                      {'loss': 1.6671, 'grad_norm': 3.9575228691101074, 'learning_rate': 0.0001140625, 'epoch': 2.29}
 46%|████▋     | 125/270 [6:25:17<7:25:47, 184.47s/it] 47%|████▋     | 126/270 [6:28:16<7:18:59, 182.92s/it]                                                      {'loss': 1.6774, 'grad_norm': 3.480006456375122, 'learning_rate': 0.00011328125, 'epoch': 2.3}
 47%|████▋     | 126/270 [6:28:16<7:18:59, 182.92s/it] 47%|████▋     | 127/270 [6:31:19<7:15:49, 182.87s/it]                                                      {'loss': 1.7339, 'grad_norm': 4.485785007476807, 'learning_rate': 0.00011250000000000001, 'epoch': 2.32}
 47%|████▋     | 127/270 [6:31:19<7:15:49, 182.87s/it] 47%|████▋     | 128/270 [6:34:22<7:13:15, 183.06s/it]                                                      {'loss': 1.758, 'grad_norm': 3.7891154289245605, 'learning_rate': 0.00011171875, 'epoch': 2.34}
 47%|████▋     | 128/270 [6:34:22<7:13:15, 183.06s/it] 48%|████▊     | 129/270 [6:37:22<7:07:30, 181.92s/it]                                                      {'loss': 1.6552, 'grad_norm': 3.53231143951416, 'learning_rate': 0.0001109375, 'epoch': 2.36}
 48%|████▊     | 129/270 [6:37:22<7:07:30, 181.92s/it] 48%|████▊     | 130/270 [6:40:31<7:09:34, 184.10s/it]                                                      {'loss': 1.6841, 'grad_norm': 3.64444899559021, 'learning_rate': 0.00011015625000000001, 'epoch': 2.38}
 48%|████▊     | 130/270 [6:40:31<7:09:34, 184.10s/it] 49%|████▊     | 131/270 [6:43:43<7:11:55, 186.44s/it]                                                      {'loss': 1.6547, 'grad_norm': 3.1707372665405273, 'learning_rate': 0.000109375, 'epoch': 2.4}
 49%|████▊     | 131/270 [6:43:43<7:11:55, 186.44s/it] 49%|████▉     | 132/270 [6:46:39<7:01:32, 183.28s/it]                                                      {'loss': 1.6833, 'grad_norm': 3.544542074203491, 'learning_rate': 0.00010859375000000001, 'epoch': 2.41}
 49%|████▉     | 132/270 [6:46:39<7:01:32, 183.28s/it] 49%|████▉     | 133/270 [6:49:45<7:00:26, 184.13s/it]                                                      {'loss': 1.7635, 'grad_norm': 3.8249614238739014, 'learning_rate': 0.00010781250000000001, 'epoch': 2.43}
 49%|████▉     | 133/270 [6:49:45<7:00:26, 184.13s/it] 50%|████▉     | 134/270 [6:52:52<6:59:43, 185.17s/it]                                                      {'loss': 1.7287, 'grad_norm': 4.008009433746338, 'learning_rate': 0.00010703125, 'epoch': 2.45}
 50%|████▉     | 134/270 [6:52:52<6:59:43, 185.17s/it] 50%|█████     | 135/270 [6:55:57<6:56:10, 184.96s/it]                                                      {'loss': 1.6624, 'grad_norm': 3.103174924850464, 'learning_rate': 0.00010625000000000001, 'epoch': 2.47}
 50%|█████     | 135/270 [6:55:57<6:56:10, 184.96s/it] 50%|█████     | 136/270 [6:58:58<6:50:15, 183.70s/it]                                                      {'loss': 1.72, 'grad_norm': 2.566654920578003, 'learning_rate': 0.00010546875, 'epoch': 2.49}
 50%|█████     | 136/270 [6:58:58<6:50:15, 183.70s/it] 51%|█████     | 137/270 [7:02:03<6:48:04, 184.09s/it]                                                      {'loss': 1.6461, 'grad_norm': 2.531344175338745, 'learning_rate': 0.0001046875, 'epoch': 2.51}
 51%|█████     | 137/270 [7:02:03<6:48:04, 184.09s/it] 51%|█████     | 138/270 [7:05:04<6:43:07, 183.24s/it]                                                      {'loss': 1.6441, 'grad_norm': 3.5683906078338623, 'learning_rate': 0.00010390625000000001, 'epoch': 2.52}
 51%|█████     | 138/270 [7:05:04<6:43:07, 183.24s/it] 51%|█████▏    | 139/270 [7:08:15<6:45:33, 185.75s/it]                                                      {'loss': 1.78, 'grad_norm': 3.8459854125976562, 'learning_rate': 0.000103125, 'epoch': 2.54}
 51%|█████▏    | 139/270 [7:08:15<6:45:33, 185.75s/it] 52%|█████▏    | 140/270 [7:11:24<6:44:09, 186.54s/it]                                                      {'loss': 1.6437, 'grad_norm': 3.337761878967285, 'learning_rate': 0.00010234375, 'epoch': 2.56}
 52%|█████▏    | 140/270 [7:11:24<6:44:09, 186.54s/it] 52%|█████▏    | 141/270 [7:14:27<6:39:05, 185.62s/it]                                                      {'loss': 1.6676, 'grad_norm': 3.9729721546173096, 'learning_rate': 0.00010156250000000001, 'epoch': 2.58}
 52%|█████▏    | 141/270 [7:14:27<6:39:05, 185.62s/it] 53%|█████▎    | 142/270 [7:17:39<6:39:58, 187.49s/it]                                                      {'loss': 1.8807, 'grad_norm': 4.809774875640869, 'learning_rate': 0.00010078125, 'epoch': 2.6}
 53%|█████▎    | 142/270 [7:17:39<6:39:58, 187.49s/it] 53%|█████▎    | 143/270 [7:20:40<6:32:19, 185.35s/it]                                                      {'loss': 1.7037, 'grad_norm': 3.283578634262085, 'learning_rate': 0.0001, 'epoch': 2.61}
 53%|█████▎    | 143/270 [7:20:40<6:32:19, 185.35s/it] 53%|█████▎    | 144/270 [7:23:43<6:27:44, 184.64s/it]                                                      {'loss': 1.6491, 'grad_norm': 3.592400550842285, 'learning_rate': 9.921875000000001e-05, 'epoch': 2.63}
 53%|█████▎    | 144/270 [7:23:43<6:27:44, 184.64s/it] 54%|█████▎    | 145/270 [7:26:45<6:23:05, 183.88s/it]                                                      {'loss': 1.6202, 'grad_norm': 3.198932647705078, 'learning_rate': 9.84375e-05, 'epoch': 2.65}
 54%|█████▎    | 145/270 [7:26:45<6:23:05, 183.88s/it] 54%|█████▍    | 146/270 [7:29:52<6:22:16, 184.97s/it]                                                      {'loss': 1.7157, 'grad_norm': 3.4191806316375732, 'learning_rate': 9.765625e-05, 'epoch': 2.67}
 54%|█████▍    | 146/270 [7:29:52<6:22:16, 184.97s/it] 54%|█████▍    | 147/270 [7:32:55<6:17:42, 184.25s/it]                                                      {'loss': 1.662, 'grad_norm': 3.1344690322875977, 'learning_rate': 9.687500000000001e-05, 'epoch': 2.69}
 54%|█████▍    | 147/270 [7:32:55<6:17:42, 184.25s/it] 55%|█████▍    | 148/270 [7:36:09<6:20:56, 187.35s/it]                                                      {'loss': 1.8083, 'grad_norm': 3.674124002456665, 'learning_rate': 9.609375e-05, 'epoch': 2.71}
 55%|█████▍    | 148/270 [7:36:09<6:20:56, 187.35s/it] 55%|█████▌    | 149/270 [7:39:21<6:20:21, 188.61s/it]                                                      {'loss': 1.616, 'grad_norm': 3.002284049987793, 'learning_rate': 9.53125e-05, 'epoch': 2.72}
 55%|█████▌    | 149/270 [7:39:21<6:20:21, 188.61s/it] 56%|█████▌    | 150/270 [7:42:40<6:23:29, 191.74s/it]                                                      {'loss': 1.7424, 'grad_norm': 4.008917331695557, 'learning_rate': 9.453125000000001e-05, 'epoch': 2.74}
 56%|█████▌    | 150/270 [7:42:40<6:23:29, 191.74s/it] 56%|█████▌    | 151/270 [7:45:49<6:18:55, 191.06s/it]                                                      {'loss': 1.7043, 'grad_norm': 3.7014219760894775, 'learning_rate': 9.375e-05, 'epoch': 2.76}
 56%|█████▌    | 151/270 [7:45:49<6:18:55, 191.06s/it] 56%|█████▋    | 152/270 [7:48:52<6:11:03, 188.68s/it]                                                      {'loss': 1.8025, 'grad_norm': 5.26801061630249, 'learning_rate': 9.296875e-05, 'epoch': 2.78}
 56%|█████▋    | 152/270 [7:48:52<6:11:03, 188.68s/it] 57%|█████▋    | 153/270 [7:51:59<6:06:51, 188.14s/it]                                                      {'loss': 1.8067, 'grad_norm': 5.580044746398926, 'learning_rate': 9.21875e-05, 'epoch': 2.8}
 57%|█████▋    | 153/270 [7:51:59<6:06:51, 188.14s/it] 57%|█████▋    | 154/270 [7:55:03<6:01:09, 186.81s/it]                                                      {'loss': 1.7656, 'grad_norm': 4.650034427642822, 'learning_rate': 9.140625e-05, 'epoch': 2.82}
 57%|█████▋    | 154/270 [7:55:03<6:01:09, 186.81s/it] 57%|█████▋    | 155/270 [7:58:10<5:58:11, 186.88s/it]                                                      {'loss': 1.7519, 'grad_norm': 4.562504291534424, 'learning_rate': 9.062500000000001e-05, 'epoch': 2.83}
 57%|█████▋    | 155/270 [7:58:10<5:58:11, 186.88s/it] 58%|█████▊    | 156/270 [8:01:06<5:48:56, 183.66s/it]                                                      {'loss': 1.6562, 'grad_norm': 4.363280296325684, 'learning_rate': 8.984375e-05, 'epoch': 2.85}
 58%|█████▊    | 156/270 [8:01:06<5:48:56, 183.66s/it] 58%|█████▊    | 157/270 [8:04:13<5:47:53, 184.72s/it]                                                      {'loss': 1.6527, 'grad_norm': 3.2260499000549316, 'learning_rate': 8.90625e-05, 'epoch': 2.87}
 58%|█████▊    | 157/270 [8:04:13<5:47:53, 184.72s/it] 59%|█████▊    | 158/270 [8:07:09<5:39:46, 182.02s/it]                                                      {'loss': 1.6992, 'grad_norm': 3.3676633834838867, 'learning_rate': 8.828125000000001e-05, 'epoch': 2.89}
 59%|█████▊    | 158/270 [8:07:09<5:39:46, 182.02s/it] 59%|█████▉    | 159/270 [8:10:15<5:38:50, 183.16s/it]                                                      {'loss': 1.7558, 'grad_norm': 3.163661479949951, 'learning_rate': 8.75e-05, 'epoch': 2.91}
 59%|█████▉    | 159/270 [8:10:15<5:38:50, 183.16s/it] 59%|█████▉    | 160/270 [8:13:18<5:35:43, 183.12s/it]                                                      {'loss': 1.6648, 'grad_norm': 3.033798933029175, 'learning_rate': 8.671875e-05, 'epoch': 2.93}
 59%|█████▉    | 160/270 [8:13:18<5:35:43, 183.12s/it] 60%|█████▉    | 161/270 [8:16:18<5:30:57, 182.18s/it]                                                      {'loss': 1.5926, 'grad_norm': 3.2523322105407715, 'learning_rate': 8.593750000000001e-05, 'epoch': 2.94}
 60%|█████▉    | 161/270 [8:16:18<5:30:57, 182.18s/it] 60%|██████    | 162/270 [8:19:32<5:34:31, 185.85s/it]                                                      {'loss': 1.6261, 'grad_norm': 3.5546793937683105, 'learning_rate': 8.515625e-05, 'epoch': 2.96}
 60%|██████    | 162/270 [8:19:32<5:34:31, 185.85s/it] 60%|██████    | 163/270 [8:22:39<5:32:05, 186.22s/it]                                                      {'loss': 1.629, 'grad_norm': 3.901667833328247, 'learning_rate': 8.4375e-05, 'epoch': 2.98}
 60%|██████    | 163/270 [8:22:39<5:32:05, 186.22s/it] 61%|██████    | 164/270 [8:25:49<5:30:29, 187.07s/it]                                                      {'loss': 1.6416, 'grad_norm': 3.8799703121185303, 'learning_rate': 8.359375000000001e-05, 'epoch': 3.0}
 61%|██████    | 164/270 [8:25:49<5:30:29, 187.07s/it] 61%|██████    | 165/270 [8:28:50<5:24:32, 185.46s/it]                                                      {'loss': 1.6392, 'grad_norm': 3.968808174133301, 'learning_rate': 8.28125e-05, 'epoch': 3.02}
 61%|██████    | 165/270 [8:28:50<5:24:32, 185.46s/it] 61%|██████▏   | 166/270 [8:31:53<5:20:17, 184.78s/it]                                                      {'loss': 1.5394, 'grad_norm': 2.9107561111450195, 'learning_rate': 8.203125e-05, 'epoch': 3.04}
 61%|██████▏   | 166/270 [8:31:53<5:20:17, 184.78s/it] 62%|██████▏   | 167/270 [8:34:55<5:15:48, 183.96s/it]                                                      {'loss': 1.5953, 'grad_norm': 2.3755624294281006, 'learning_rate': 8.125000000000001e-05, 'epoch': 3.05}
 62%|██████▏   | 167/270 [8:34:55<5:15:48, 183.96s/it] 62%|██████▏   | 168/270 [8:38:07<5:16:33, 186.21s/it]                                                      {'loss': 1.4931, 'grad_norm': 2.2432503700256348, 'learning_rate': 8.046875e-05, 'epoch': 3.07}
 62%|██████▏   | 168/270 [8:38:07<5:16:33, 186.21s/it] 63%|██████▎   | 169/270 [8:41:08<5:10:47, 184.63s/it]                                                      {'loss': 1.5698, 'grad_norm': 3.244428873062134, 'learning_rate': 7.96875e-05, 'epoch': 3.09}
 63%|██████▎   | 169/270 [8:41:08<5:10:47, 184.63s/it] 63%|██████▎   | 170/270 [8:44:16<5:09:40, 185.81s/it]                                                      {'loss': 1.5499, 'grad_norm': 2.429729461669922, 'learning_rate': 7.890625000000001e-05, 'epoch': 3.11}
 63%|██████▎   | 170/270 [8:44:16<5:09:40, 185.81s/it] 63%|██████▎   | 171/270 [8:47:23<5:06:47, 185.93s/it]                                                      {'loss': 1.6404, 'grad_norm': 3.7638204097747803, 'learning_rate': 7.8125e-05, 'epoch': 3.13}
 63%|██████▎   | 171/270 [8:47:23<5:06:47, 185.93s/it] 64%|██████▎   | 172/270 [8:50:25<5:01:50, 184.80s/it]                                                      {'loss': 1.5628, 'grad_norm': 3.8760628700256348, 'learning_rate': 7.734375e-05, 'epoch': 3.15}
 64%|██████▎   | 172/270 [8:50:25<5:01:50, 184.80s/it] 64%|██████▍   | 173/270 [8:53:28<4:58:00, 184.34s/it]                                                      {'loss': 1.5308, 'grad_norm': 3.1175925731658936, 'learning_rate': 7.65625e-05, 'epoch': 3.16}
 64%|██████▍   | 173/270 [8:53:28<4:58:00, 184.34s/it] 64%|██████▍   | 174/270 [8:56:38<4:57:47, 186.12s/it]                                                      {'loss': 1.5625, 'grad_norm': 3.4154856204986572, 'learning_rate': 7.578125e-05, 'epoch': 3.18}
 64%|██████▍   | 174/270 [8:56:38<4:57:47, 186.12s/it] 65%|██████▍   | 175/270 [8:59:46<4:55:13, 186.46s/it]                                                      {'loss': 1.4983, 'grad_norm': 2.6867082118988037, 'learning_rate': 7.500000000000001e-05, 'epoch': 3.2}
 65%|██████▍   | 175/270 [8:59:46<4:55:13, 186.46s/it] 65%|██████▌   | 176/270 [9:02:50<4:51:03, 185.79s/it]                                                      {'loss': 1.526, 'grad_norm': 2.7335190773010254, 'learning_rate': 7.421875e-05, 'epoch': 3.22}
 65%|██████▌   | 176/270 [9:02:50<4:51:03, 185.79s/it] 66%|██████▌   | 177/270 [9:05:55<4:47:45, 185.65s/it]                                                      {'loss': 1.5473, 'grad_norm': 2.946519136428833, 'learning_rate': 7.34375e-05, 'epoch': 3.24}
 66%|██████▌   | 177/270 [9:05:55<4:47:45, 185.65s/it] 66%|██████▌   | 178/270 [9:09:12<4:49:41, 188.93s/it]                                                      {'loss': 1.5949, 'grad_norm': 3.3688392639160156, 'learning_rate': 7.265625000000001e-05, 'epoch': 3.25}
 66%|██████▌   | 178/270 [9:09:12<4:49:41, 188.93s/it] 66%|██████▋   | 179/270 [9:12:18<4:45:20, 188.13s/it]                                                      {'loss': 1.5311, 'grad_norm': 3.5794637203216553, 'learning_rate': 7.1875e-05, 'epoch': 3.27}
 66%|██████▋   | 179/270 [9:12:18<4:45:20, 188.13s/it] 67%|██████▋   | 180/270 [9:15:16<4:37:35, 185.06s/it]                                                      {'loss': 1.5231, 'grad_norm': 3.0429797172546387, 'learning_rate': 7.109375e-05, 'epoch': 3.29}
 67%|██████▋   | 180/270 [9:15:16<4:37:35, 185.06s/it] 67%|██████▋   | 181/270 [9:18:27<4:37:23, 187.01s/it]                                                      {'loss': 1.4857, 'grad_norm': 2.0500526428222656, 'learning_rate': 7.031250000000001e-05, 'epoch': 3.31}
 67%|██████▋   | 181/270 [9:18:27<4:37:23, 187.01s/it] 67%|██████▋   | 182/270 [9:21:35<4:34:37, 187.24s/it]                                                      {'loss': 1.5583, 'grad_norm': 4.001841068267822, 'learning_rate': 6.953125e-05, 'epoch': 3.33}
 67%|██████▋   | 182/270 [9:21:35<4:34:37, 187.24s/it] 68%|██████▊   | 183/270 [9:24:42<4:31:10, 187.02s/it]                                                      {'loss': 1.5686, 'grad_norm': 2.8661820888519287, 'learning_rate': 6.875e-05, 'epoch': 3.35}
 68%|██████▊   | 183/270 [9:24:42<4:31:10, 187.02s/it] 68%|██████▊   | 184/270 [9:27:46<4:26:56, 186.24s/it]                                                      {'loss': 1.5104, 'grad_norm': 4.230047702789307, 'learning_rate': 6.796875000000001e-05, 'epoch': 3.36}
 68%|██████▊   | 184/270 [9:27:46<4:26:56, 186.24s/it] 69%|██████▊   | 185/270 [9:30:45<4:20:37, 183.97s/it]                                                      {'loss': 1.6218, 'grad_norm': 3.611041784286499, 'learning_rate': 6.71875e-05, 'epoch': 3.38}
 69%|██████▊   | 185/270 [9:30:45<4:20:37, 183.97s/it] 69%|██████▉   | 186/270 [9:33:49<4:17:29, 183.93s/it]                                                      {'loss': 1.5531, 'grad_norm': 3.306086301803589, 'learning_rate': 6.640625e-05, 'epoch': 3.4}
 69%|██████▉   | 186/270 [9:33:49<4:17:29, 183.93s/it] 69%|██████▉   | 187/270 [9:36:53<4:14:32, 184.01s/it]                                                      {'loss': 1.4934, 'grad_norm': 2.574059247970581, 'learning_rate': 6.562500000000001e-05, 'epoch': 3.42}
 69%|██████▉   | 187/270 [9:36:53<4:14:32, 184.01s/it] 70%|██████▉   | 188/270 [9:39:57<4:11:30, 184.03s/it]                                                      {'loss': 1.5301, 'grad_norm': 3.2432236671447754, 'learning_rate': 6.484375e-05, 'epoch': 3.44}
 70%|██████▉   | 188/270 [9:39:57<4:11:30, 184.03s/it] 70%|███████   | 189/270 [9:43:01<4:08:38, 184.18s/it]                                                      {'loss': 1.5437, 'grad_norm': 2.8706274032592773, 'learning_rate': 6.40625e-05, 'epoch': 3.46}
 70%|███████   | 189/270 [9:43:01<4:08:38, 184.18s/it] 70%|███████   | 190/270 [9:46:03<4:04:36, 183.46s/it]                                                      {'loss': 1.6202, 'grad_norm': 4.246726036071777, 'learning_rate': 6.328125e-05, 'epoch': 3.47}
 70%|███████   | 190/270 [9:46:03<4:04:36, 183.46s/it] 71%|███████   | 191/270 [9:49:07<4:01:38, 183.52s/it]                                                      {'loss': 1.5336, 'grad_norm': 3.7939040660858154, 'learning_rate': 6.25e-05, 'epoch': 3.49}
 71%|███████   | 191/270 [9:49:07<4:01:38, 183.52s/it] 71%|███████   | 192/270 [9:52:11<3:58:58, 183.83s/it]                                                      {'loss': 1.5524, 'grad_norm': 5.144968509674072, 'learning_rate': 6.171875e-05, 'epoch': 3.51}
 71%|███████   | 192/270 [9:52:11<3:58:58, 183.83s/it] 71%|███████▏  | 193/270 [9:55:20<3:57:49, 185.31s/it]                                                      {'loss': 1.4921, 'grad_norm': 3.2342002391815186, 'learning_rate': 6.0937500000000004e-05, 'epoch': 3.53}
 71%|███████▏  | 193/270 [9:55:20<3:57:49, 185.31s/it] 72%|███████▏  | 194/270 [9:58:32<3:57:11, 187.26s/it]                                                      {'loss': 1.6136, 'grad_norm': 3.799018383026123, 'learning_rate': 6.015625e-05, 'epoch': 3.55}
 72%|███████▏  | 194/270 [9:58:32<3:57:11, 187.26s/it] 72%|███████▏  | 195/270 [10:01:38<3:53:42, 186.97s/it]                                                       {'loss': 1.4901, 'grad_norm': 2.8974905014038086, 'learning_rate': 5.9375e-05, 'epoch': 3.57}
 72%|███████▏  | 195/270 [10:01:38<3:53:42, 186.97s/it] 73%|███████▎  | 196/270 [10:04:41<3:49:10, 185.82s/it]                                                       {'loss': 1.5863, 'grad_norm': 3.747488260269165, 'learning_rate': 5.8593750000000005e-05, 'epoch': 3.58}
 73%|███████▎  | 196/270 [10:04:41<3:49:10, 185.82s/it] 73%|███████▎  | 197/270 [10:07:40<3:43:18, 183.54s/it]                                                       {'loss': 1.4778, 'grad_norm': 2.699429750442505, 'learning_rate': 5.78125e-05, 'epoch': 3.6}
 73%|███████▎  | 197/270 [10:07:40<3:43:18, 183.54s/it] 73%|███████▎  | 198/270 [10:10:38<3:38:14, 181.87s/it]                                                       {'loss': 1.6306, 'grad_norm': 2.9829797744750977, 'learning_rate': 5.703125e-05, 'epoch': 3.62}
 73%|███████▎  | 198/270 [10:10:38<3:38:14, 181.87s/it] 74%|███████▎  | 199/270 [10:13:39<3:35:00, 181.69s/it]                                                       {'loss': 1.5287, 'grad_norm': 2.763518810272217, 'learning_rate': 5.6250000000000005e-05, 'epoch': 3.64}
 74%|███████▎  | 199/270 [10:13:39<3:35:00, 181.69s/it] 74%|███████▍  | 200/270 [10:16:44<3:33:07, 182.68s/it]                                                       {'loss': 1.5358, 'grad_norm': 2.4786159992218018, 'learning_rate': 5.546875e-05, 'epoch': 3.66}
 74%|███████▍  | 200/270 [10:16:44<3:33:07, 182.68s/it] 74%|███████▍  | 201/270 [10:19:58<3:33:53, 185.99s/it]                                                       {'loss': 1.5012, 'grad_norm': 2.5641746520996094, 'learning_rate': 5.46875e-05, 'epoch': 3.68}
 74%|███████▍  | 201/270 [10:19:58<3:33:53, 185.99s/it] 75%|███████▍  | 202/270 [10:23:12<3:33:35, 188.46s/it]                                                       {'loss': 1.5933, 'grad_norm': 3.366305351257324, 'learning_rate': 5.3906250000000006e-05, 'epoch': 3.69}
 75%|███████▍  | 202/270 [10:23:12<3:33:35, 188.46s/it] 75%|███████▌  | 203/270 [10:26:17<3:29:21, 187.49s/it]                                                       {'loss': 1.5856, 'grad_norm': 2.8172852993011475, 'learning_rate': 5.3125000000000004e-05, 'epoch': 3.71}
 75%|███████▌  | 203/270 [10:26:17<3:29:21, 187.49s/it] 76%|███████▌  | 204/270 [10:29:19<3:24:23, 185.80s/it]                                                       {'loss': 1.5287, 'grad_norm': 2.912554979324341, 'learning_rate': 5.234375e-05, 'epoch': 3.73}
 76%|███████▌  | 204/270 [10:29:19<3:24:23, 185.80s/it] 76%|███████▌  | 205/270 [10:32:25<3:21:27, 185.96s/it]                                                       {'loss': 1.5567, 'grad_norm': 3.3477821350097656, 'learning_rate': 5.15625e-05, 'epoch': 3.75}
 76%|███████▌  | 205/270 [10:32:25<3:21:27, 185.96s/it] 76%|███████▋  | 206/270 [10:35:34<3:19:14, 186.79s/it]                                                       {'loss': 1.5601, 'grad_norm': 2.9587185382843018, 'learning_rate': 5.0781250000000004e-05, 'epoch': 3.77}
 76%|███████▋  | 206/270 [10:35:34<3:19:14, 186.79s/it] 77%|███████▋  | 207/270 [10:38:40<3:16:00, 186.67s/it]                                                       {'loss': 1.5142, 'grad_norm': 3.0246965885162354, 'learning_rate': 5e-05, 'epoch': 3.79}
 77%|███████▋  | 207/270 [10:38:40<3:16:00, 186.67s/it] 77%|███████▋  | 208/270 [10:41:40<3:10:46, 184.62s/it]                                                       {'loss': 1.5743, 'grad_norm': 2.6608939170837402, 'learning_rate': 4.921875e-05, 'epoch': 3.8}
 77%|███████▋  | 208/270 [10:41:40<3:10:46, 184.62s/it] 77%|███████▋  | 209/270 [10:44:46<3:07:58, 184.90s/it]                                                       {'loss': 1.5704, 'grad_norm': 4.221491813659668, 'learning_rate': 4.8437500000000005e-05, 'epoch': 3.82}
 77%|███████▋  | 209/270 [10:44:46<3:07:58, 184.90s/it] 78%|███████▊  | 210/270 [10:47:48<3:04:05, 184.10s/it]                                                       {'loss': 1.5775, 'grad_norm': 2.734755754470825, 'learning_rate': 4.765625e-05, 'epoch': 3.84}
 78%|███████▊  | 210/270 [10:47:48<3:04:05, 184.10s/it] 78%|███████▊  | 211/270 [10:50:53<3:01:12, 184.29s/it]                                                       {'loss': 1.5119, 'grad_norm': 2.1616129875183105, 'learning_rate': 4.6875e-05, 'epoch': 3.86}
 78%|███████▊  | 211/270 [10:50:53<3:01:12, 184.29s/it] 79%|███████▊  | 212/270 [10:54:02<2:59:35, 185.79s/it]                                                       {'loss': 1.5753, 'grad_norm': 2.9770827293395996, 'learning_rate': 4.609375e-05, 'epoch': 3.88}
 79%|███████▊  | 212/270 [10:54:02<2:59:35, 185.79s/it] 79%|███████▉  | 213/270 [10:57:06<2:56:00, 185.28s/it]                                                       {'loss': 1.5062, 'grad_norm': 3.2355964183807373, 'learning_rate': 4.5312500000000004e-05, 'epoch': 3.89}
 79%|███████▉  | 213/270 [10:57:06<2:56:00, 185.28s/it] 79%|███████▉  | 214/270 [11:00:08<2:51:54, 184.19s/it]                                                       {'loss': 1.56, 'grad_norm': 2.5581748485565186, 'learning_rate': 4.453125e-05, 'epoch': 3.91}
 79%|███████▉  | 214/270 [11:00:08<2:51:54, 184.19s/it] 80%|███████▉  | 215/270 [11:03:17<2:50:09, 185.62s/it]                                                       {'loss': 1.5388, 'grad_norm': 3.1986987590789795, 'learning_rate': 4.375e-05, 'epoch': 3.93}
 80%|███████▉  | 215/270 [11:03:17<2:50:09, 185.62s/it] 80%|████████  | 216/270 [11:06:20<2:46:19, 184.81s/it]                                                       {'loss': 1.5734, 'grad_norm': 2.8833718299865723, 'learning_rate': 4.2968750000000004e-05, 'epoch': 3.95}
 80%|████████  | 216/270 [11:06:20<2:46:19, 184.81s/it] 80%|████████  | 217/270 [11:09:19<2:41:47, 183.15s/it]                                                       {'loss': 1.5952, 'grad_norm': 3.4124503135681152, 'learning_rate': 4.21875e-05, 'epoch': 3.97}
 80%|████████  | 217/270 [11:09:19<2:41:47, 183.15s/it] 81%|████████  | 218/270 [11:12:13<2:36:20, 180.39s/it]                                                       {'loss': 1.5609, 'grad_norm': 3.2109739780426025, 'learning_rate': 4.140625e-05, 'epoch': 3.99}
 81%|████████  | 218/270 [11:12:13<2:36:20, 180.39s/it] 81%|████████  | 219/270 [11:15:13<2:33:19, 180.39s/it]                                                       {'loss': 1.5819, 'grad_norm': 2.653583526611328, 'learning_rate': 4.0625000000000005e-05, 'epoch': 4.0}
 81%|████████  | 219/270 [11:15:13<2:33:19, 180.39s/it] 81%|████████▏ | 220/270 [11:18:08<2:28:52, 178.65s/it]                                                       {'loss': 1.4505, 'grad_norm': 1.5332704782485962, 'learning_rate': 3.984375e-05, 'epoch': 4.02}
 81%|████████▏ | 220/270 [11:18:08<2:28:52, 178.65s/it] 82%|████████▏ | 221/270 [11:21:15<2:27:51, 181.06s/it]                                                       {'loss': 1.4865, 'grad_norm': 1.657728910446167, 'learning_rate': 3.90625e-05, 'epoch': 4.04}
 82%|████████▏ | 221/270 [11:21:15<2:27:51, 181.06s/it] 82%|████████▏ | 222/270 [11:24:24<2:26:47, 183.50s/it]                                                       {'loss': 1.4552, 'grad_norm': 1.6128101348876953, 'learning_rate': 3.828125e-05, 'epoch': 4.06}
 82%|████████▏ | 222/270 [11:24:24<2:26:47, 183.50s/it] 83%|████████▎ | 223/270 [11:27:29<2:24:03, 183.91s/it]                                                       {'loss': 1.4694, 'grad_norm': 1.4585856199264526, 'learning_rate': 3.7500000000000003e-05, 'epoch': 4.08}
 83%|████████▎ | 223/270 [11:27:29<2:24:03, 183.91s/it] 83%|████████▎ | 224/270 [11:30:30<2:20:25, 183.17s/it]                                                       {'loss': 1.4995, 'grad_norm': 2.9269416332244873, 'learning_rate': 3.671875e-05, 'epoch': 4.1}
 83%|████████▎ | 224/270 [11:30:30<2:20:25, 183.17s/it] 83%|████████▎ | 225/270 [11:33:34<2:17:34, 183.43s/it]                                                       {'loss': 1.5027, 'grad_norm': 3.2729249000549316, 'learning_rate': 3.59375e-05, 'epoch': 4.11}
 83%|████████▎ | 225/270 [11:33:34<2:17:34, 183.43s/it] 84%|████████▎ | 226/270 [11:36:40<2:14:58, 184.05s/it]                                                       {'loss': 1.4713, 'grad_norm': 2.402620792388916, 'learning_rate': 3.5156250000000004e-05, 'epoch': 4.13}
 84%|████████▎ | 226/270 [11:36:40<2:14:58, 184.05s/it] 84%|████████▍ | 227/270 [11:39:48<2:12:52, 185.40s/it]                                                       {'loss': 1.4872, 'grad_norm': 3.189312696456909, 'learning_rate': 3.4375e-05, 'epoch': 4.15}
 84%|████████▍ | 227/270 [11:39:48<2:12:52, 185.40s/it] 84%|████████▍ | 228/270 [11:42:57<2:10:33, 186.52s/it]                                                       {'loss': 1.4882, 'grad_norm': 2.303143262863159, 'learning_rate': 3.359375e-05, 'epoch': 4.17}
 84%|████████▍ | 228/270 [11:42:57<2:10:33, 186.52s/it] 85%|████████▍ | 229/270 [11:46:07<2:08:05, 187.44s/it]                                                       {'loss': 1.4535, 'grad_norm': 3.4557180404663086, 'learning_rate': 3.2812500000000005e-05, 'epoch': 4.19}
 85%|████████▍ | 229/270 [11:46:07<2:08:05, 187.44s/it] 85%|████████▌ | 230/270 [11:49:10<2:04:07, 186.18s/it]                                                       {'loss': 1.449, 'grad_norm': 2.038560390472412, 'learning_rate': 3.203125e-05, 'epoch': 4.21}
 85%|████████▌ | 230/270 [11:49:10<2:04:07, 186.18s/it] 86%|████████▌ | 231/270 [11:52:08<1:59:29, 183.83s/it]                                                       {'loss': 1.4521, 'grad_norm': 2.825012683868408, 'learning_rate': 3.125e-05, 'epoch': 4.22}
 86%|████████▌ | 231/270 [11:52:08<1:59:29, 183.83s/it] 86%|████████▌ | 232/270 [11:55:09<1:55:45, 182.77s/it]                                                       {'loss': 1.4778, 'grad_norm': 3.062028646469116, 'learning_rate': 3.0468750000000002e-05, 'epoch': 4.24}
 86%|████████▌ | 232/270 [11:55:09<1:55:45, 182.77s/it] 86%|████████▋ | 233/270 [11:58:10<1:52:23, 182.27s/it]                                                       {'loss': 1.4358, 'grad_norm': 1.8103184700012207, 'learning_rate': 2.96875e-05, 'epoch': 4.26}
 86%|████████▋ | 233/270 [11:58:10<1:52:23, 182.27s/it] 87%|████████▋ | 234/270 [12:01:22<1:51:08, 185.22s/it]                                                       {'loss': 1.4902, 'grad_norm': 1.9001948833465576, 'learning_rate': 2.890625e-05, 'epoch': 4.28}
 87%|████████▋ | 234/270 [12:01:22<1:51:08, 185.22s/it] 87%|████████▋ | 235/270 [12:04:25<1:47:35, 184.46s/it]                                                       {'loss': 1.4387, 'grad_norm': 1.815516471862793, 'learning_rate': 2.8125000000000003e-05, 'epoch': 4.3}
 87%|████████▋ | 235/270 [12:04:25<1:47:35, 184.46s/it] 87%|████████▋ | 236/270 [12:07:29<1:44:29, 184.41s/it]                                                       {'loss': 1.4699, 'grad_norm': 2.2597978115081787, 'learning_rate': 2.734375e-05, 'epoch': 4.32}
 87%|████████▋ | 236/270 [12:07:29<1:44:29, 184.41s/it] 88%|████████▊ | 237/270 [12:10:33<1:41:24, 184.39s/it]                                                       {'loss': 1.4167, 'grad_norm': 1.5316368341445923, 'learning_rate': 2.6562500000000002e-05, 'epoch': 4.33}
 88%|████████▊ | 237/270 [12:10:33<1:41:24, 184.39s/it] 88%|████████▊ | 238/270 [12:13:45<1:39:31, 186.62s/it]                                                       {'loss': 1.4134, 'grad_norm': 1.2665679454803467, 'learning_rate': 2.578125e-05, 'epoch': 4.35}
 88%|████████▊ | 238/270 [12:13:45<1:39:31, 186.62s/it] 89%|████████▊ | 239/270 [12:16:50<1:36:09, 186.12s/it]                                                       {'loss': 1.4719, 'grad_norm': 2.5139849185943604, 'learning_rate': 2.5e-05, 'epoch': 4.37}
 89%|████████▊ | 239/270 [12:16:50<1:36:09, 186.12s/it] 89%|████████▉ | 240/270 [12:19:58<1:33:17, 186.57s/it]                                                       {'loss': 1.457, 'grad_norm': 2.1602365970611572, 'learning_rate': 2.4218750000000003e-05, 'epoch': 4.39}
 89%|████████▉ | 240/270 [12:19:58<1:33:17, 186.57s/it] 89%|████████▉ | 241/270 [12:23:03<1:29:58, 186.15s/it]                                                       {'loss': 1.4955, 'grad_norm': 2.976597547531128, 'learning_rate': 2.34375e-05, 'epoch': 4.41}
 89%|████████▉ | 241/270 [12:23:03<1:29:58, 186.15s/it] 90%|████████▉ | 242/270 [12:26:07<1:26:38, 185.66s/it]                                                       {'loss': 1.4705, 'grad_norm': 2.7119596004486084, 'learning_rate': 2.2656250000000002e-05, 'epoch': 4.43}
 90%|████████▉ | 242/270 [12:26:07<1:26:38, 185.66s/it] 90%|█████████ | 243/270 [12:29:12<1:23:21, 185.23s/it]                                                       {'loss': 1.436, 'grad_norm': 1.7365758419036865, 'learning_rate': 2.1875e-05, 'epoch': 4.44}
 90%|█████████ | 243/270 [12:29:12<1:23:21, 185.23s/it] 90%|█████████ | 244/270 [12:32:17<1:20:14, 185.19s/it]                                                       {'loss': 1.4824, 'grad_norm': 2.194836378097534, 'learning_rate': 2.109375e-05, 'epoch': 4.46}
 90%|█████████ | 244/270 [12:32:17<1:20:14, 185.19s/it] 91%|█████████ | 245/270 [12:35:19<1:16:47, 184.31s/it]                                                       {'loss': 1.5094, 'grad_norm': 3.6022534370422363, 'learning_rate': 2.0312500000000002e-05, 'epoch': 4.48}
 91%|█████████ | 245/270 [12:35:19<1:16:47, 184.31s/it] 91%|█████████ | 246/270 [12:38:26<1:14:00, 185.04s/it]                                                       {'loss': 1.5192, 'grad_norm': 2.987154960632324, 'learning_rate': 1.953125e-05, 'epoch': 4.5}
 91%|█████████ | 246/270 [12:38:26<1:14:00, 185.04s/it] 91%|█████████▏| 247/270 [12:41:41<1:12:04, 188.01s/it]                                                       {'loss': 1.545, 'grad_norm': 2.2724175453186035, 'learning_rate': 1.8750000000000002e-05, 'epoch': 4.52}
 91%|█████████▏| 247/270 [12:41:41<1:12:04, 188.01s/it] 92%|█████████▏| 248/270 [12:44:47<1:08:47, 187.62s/it]                                                       {'loss': 1.4996, 'grad_norm': 2.5278711318969727, 'learning_rate': 1.796875e-05, 'epoch': 4.53}
 92%|█████████▏| 248/270 [12:44:47<1:08:47, 187.62s/it] 92%|█████████▏| 249/270 [12:48:00<1:06:12, 189.14s/it]                                                       {'loss': 1.4791, 'grad_norm': 2.5703368186950684, 'learning_rate': 1.71875e-05, 'epoch': 4.55}
 92%|█████████▏| 249/270 [12:48:00<1:06:12, 189.14s/it] 93%|█████████▎| 250/270 [12:51:15<1:03:35, 190.79s/it]                                                       {'loss': 1.4629, 'grad_norm': 2.1713151931762695, 'learning_rate': 1.6406250000000002e-05, 'epoch': 4.57}
 93%|█████████▎| 250/270 [12:51:15<1:03:35, 190.79s/it] 93%|█████████▎| 251/270 [12:54:17<59:39, 188.39s/it]                                                       {'loss': 1.4225, 'grad_norm': 1.5244534015655518, 'learning_rate': 1.5625e-05, 'epoch': 4.59}
 93%|█████████▎| 251/270 [12:54:17<59:39, 188.39s/it] 93%|█████████▎| 252/270 [12:57:15<55:35, 185.28s/it]                                                     {'loss': 1.4447, 'grad_norm': 1.755815863609314, 'learning_rate': 1.484375e-05, 'epoch': 4.61}
 93%|█████████▎| 252/270 [12:57:15<55:35, 185.28s/it] 94%|█████████▎| 253/270 [13:00:21<52:29, 185.28s/it]                                                     {'loss': 1.4625, 'grad_norm': 2.4135470390319824, 'learning_rate': 1.4062500000000001e-05, 'epoch': 4.63}
 94%|█████████▎| 253/270 [13:00:21<52:29, 185.28s/it] 94%|█████████▍| 254/270 [13:03:19<48:52, 183.29s/it]                                                     {'loss': 1.4386, 'grad_norm': 1.755456805229187, 'learning_rate': 1.3281250000000001e-05, 'epoch': 4.64}
 94%|█████████▍| 254/270 [13:03:19<48:52, 183.29s/it] 94%|█████████▍| 255/270 [13:06:26<46:03, 184.25s/it]                                                     {'loss': 1.4272, 'grad_norm': 1.92133367061615, 'learning_rate': 1.25e-05, 'epoch': 4.66}
 94%|█████████▍| 255/270 [13:06:26<46:03, 184.25s/it] 95%|█████████▍| 256/270 [13:09:25<42:39, 182.83s/it]                                                     {'loss': 1.4584, 'grad_norm': 2.5012624263763428, 'learning_rate': 1.171875e-05, 'epoch': 4.68}
 95%|█████████▍| 256/270 [13:09:25<42:39, 182.83s/it] 95%|█████████▌| 257/270 [13:12:28<39:37, 182.90s/it]                                                     {'loss': 1.48, 'grad_norm': 1.7960132360458374, 'learning_rate': 1.09375e-05, 'epoch': 4.7}
 95%|█████████▌| 257/270 [13:12:28<39:37, 182.90s/it] 96%|█████████▌| 258/270 [13:15:30<36:30, 182.57s/it]                                                     {'loss': 1.4631, 'grad_norm': 1.788862705230713, 'learning_rate': 1.0156250000000001e-05, 'epoch': 4.72}
 96%|█████████▌| 258/270 [13:15:30<36:30, 182.57s/it] 96%|█████████▌| 259/270 [13:18:33<33:27, 182.48s/it]                                                     {'loss': 1.4709, 'grad_norm': 1.4128189086914062, 'learning_rate': 9.375000000000001e-06, 'epoch': 4.74}
 96%|█████████▌| 259/270 [13:18:33<33:27, 182.48s/it] 96%|█████████▋| 260/270 [13:21:34<30:22, 182.21s/it]                                                     {'loss': 1.4623, 'grad_norm': 2.5727648735046387, 'learning_rate': 8.59375e-06, 'epoch': 4.75}
 96%|█████████▋| 260/270 [13:21:34<30:22, 182.21s/it] 97%|█████████▋| 261/270 [13:24:35<27:17, 181.94s/it]                                                     {'loss': 1.4546, 'grad_norm': 2.2945172786712646, 'learning_rate': 7.8125e-06, 'epoch': 4.77}
 97%|█████████▋| 261/270 [13:24:35<27:17, 181.94s/it] 97%|█████████▋| 262/270 [13:27:45<24:33, 184.23s/it]                                                     {'loss': 1.4222, 'grad_norm': 2.8114001750946045, 'learning_rate': 7.031250000000001e-06, 'epoch': 4.79}
 97%|█████████▋| 262/270 [13:27:45<24:33, 184.23s/it] 97%|█████████▋| 263/270 [13:30:43<21:15, 182.22s/it]                                                     {'loss': 1.4709, 'grad_norm': 2.484503746032715, 'learning_rate': 6.25e-06, 'epoch': 4.81}
 97%|█████████▋| 263/270 [13:30:43<21:15, 182.22s/it] 98%|█████████▊| 264/270 [13:33:51<18:24, 184.04s/it]                                                     {'loss': 1.4576, 'grad_norm': 3.2153122425079346, 'learning_rate': 5.46875e-06, 'epoch': 4.83}
 98%|█████████▊| 264/270 [13:33:51<18:24, 184.04s/it] 98%|█████████▊| 265/270 [13:36:53<15:16, 183.40s/it]                                                     {'loss': 1.4636, 'grad_norm': 3.837122678756714, 'learning_rate': 4.6875000000000004e-06, 'epoch': 4.85}
 98%|█████████▊| 265/270 [13:36:53<15:16, 183.40s/it] 99%|█████████▊| 266/270 [13:39:55<12:12, 183.18s/it]                                                     {'loss': 1.4967, 'grad_norm': 3.953275442123413, 'learning_rate': 3.90625e-06, 'epoch': 4.86}
 99%|█████████▊| 266/270 [13:39:55<12:12, 183.18s/it] 99%|█████████▉| 267/270 [13:43:04<09:14, 184.77s/it]                                                     {'loss': 1.4497, 'grad_norm': 1.7170103788375854, 'learning_rate': 3.125e-06, 'epoch': 4.88}
 99%|█████████▉| 267/270 [13:43:04<09:14, 184.77s/it] 99%|█████████▉| 268/270 [13:46:03<06:06, 183.06s/it]                                                     {'loss': 1.4588, 'grad_norm': 2.2358038425445557, 'learning_rate': 2.3437500000000002e-06, 'epoch': 4.9}
 99%|█████████▉| 268/270 [13:46:03<06:06, 183.06s/it]100%|█████████▉| 269/270 [13:49:04<03:02, 182.54s/it]                                                     {'loss': 1.4382, 'grad_norm': 2.972158908843994, 'learning_rate': 1.5625e-06, 'epoch': 4.92}
100%|█████████▉| 269/270 [13:49:04<03:02, 182.54s/it]100%|██████████| 270/270 [13:52:10<00:00, 183.39s/it]                                                     {'loss': 1.4774, 'grad_norm': 2.3763763904571533, 'learning_rate': 7.8125e-07, 'epoch': 4.94}
100%|██████████| 270/270 [13:52:10<00:00, 183.39s/it]                                                     {'train_runtime': 49958.2623, 'train_samples_per_second': 0.35, 'train_steps_per_second': 0.005, 'train_loss': 1.7940338417335793, 'epoch': 4.94}
100%|██████████| 270/270 [13:52:38<00:00, 183.39s/it]100%|██████████| 270/270 [13:52:38<00:00, 185.03s/it]
